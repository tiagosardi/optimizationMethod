{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metodoNewton.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP94E+9tWi5HgzNFXsLlak1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagosardi/optimizationMethod/blob/main/metodoNewton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbuWOQ4ZqyW9"
      },
      "source": [
        "<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>\n",
        "\n",
        "\n",
        "Para situações em que o valor do gradiente não exista, $$\\nexists\\nabla \\hat{f}(x),$$ vamos estimar o valor do gradiente aplicando: \n",
        "$$\n",
        "\\lim_{delta \\to 0} \\frac{f(x+delta)-f(x)}{delta}\n",
        "$$\n",
        "\n",
        "Onde estimaremos numa aproximação curta do valor real do gradiente. Para isso, criaremos uma função quadrática que possa convergir com o mínimo local da função original.\n",
        "\n",
        "Vamos utilizar o método de Newton. Partiremos da minimização da expansão da série de Taylor. Então, utilizaremos o gradiente igual a zero da função de Taylor:\n",
        "\n",
        "$$min \\hat{f}(x) = f(x_i) + f'(x_i)(x-x_i) + \\frac{f''(x_i)}{2!}(x-x_i)^2$$\n",
        "\n",
        "$$\\hat{f}'(x)=0-f'(x_i)-f''(x_i)(x- x_i) = 0$$\n",
        "\n",
        "$$x = x_i - \\frac{f'(x)}{f''(x)}$$\n",
        "\n",
        "Repare que consigo ir para o mínimo da função quadrática usando um método que estima o gradiente. Se a função for quadrática, conseguiremos convergir em apenas uma iteração.\n",
        "\n",
        "Portanto, para efetuar as etapas deste processo para uma variável, seguimos a seguinte receita:\n",
        "\n",
        "1. Escolho um X inicial\n",
        "2. Escolho a direção da busca $$\\tilde{s}=f'(x)$$\n",
        "3. Atualiza x $$x=x-\\frac{1}{f(\\tilde{x})}f'(x)$$\n",
        "4. Ir para 2 até atingir critério de parada\n",
        "\n",
        "Para várias variáveis, resolveremos utilizando a Hessiana:\n",
        "\n",
        "$$\\tilde{x} = \\tilde{x} - H^{-1} \\nabla{f}(\\tilde{x})$$\n",
        "\n",
        "Utilizamos a inversa da Hessiana, pois é a maneira algebricamente correta de calcular a ração do vetor gradiente com a hessiana. \n",
        "Temos o problema da Hessiana ser singular (determinante 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie0gmxnqqvVS"
      },
      "source": [
        ""
      ]
    }
  ]
}